<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;speedpromise.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:true,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:true,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;buttons&quot;,&quot;active&quot;:&quot;gitalk&quot;,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null,&quot;activeClass&quot;:&quot;gitalk&quot;},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:true}}</script><script src="/js/config.js"></script><meta name="description" content="爬虫是 IO 密集型任务，当使用 requests 库爬虫某个站点，发出请求后必须等待网站返回响应，才能继续运行，那有没有可以优化的方案呢？本章来了解一下异步爬虫的概念。"><meta property="og:type" content="article"><meta property="og:title" content="爬虫笔记六 -- 异步爬虫"><meta property="og:url" content="https://speedpromise.github.io/archives/57744bfb.html"><meta property="og:site_name" content="Hyacinthの博客"><meta property="og:description" content="爬虫是 IO 密集型任务，当使用 requests 库爬虫某个站点，发出请求后必须等待网站返回响应，才能继续运行，那有没有可以优化的方案呢？本章来了解一下异步爬虫的概念。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/AdlUeT3QpzktrEh.png"><meta property="og:image" content="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/nwZdlBrSsU58hJi.png"><meta property="og:image" content="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/Hw7Vxz16nWrBYFX.png"><meta property="og:image" content="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/52dkJOrNYMIfaDn.png"><meta property="article:published_time" content="2022-02-22T12:09:20.000Z"><meta property="article:modified_time" content="2022-03-28T04:41:38.685Z"><meta property="article:author" content="Hyacinth"><meta property="article:tag" content="爬虫笔记"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/AdlUeT3QpzktrEh.png"><link rel="canonical" href="https://speedpromise.github.io/archives/57744bfb.html"><script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;speedpromise.github.io&#x2F;archives&#x2F;57744bfb.html&quot;,&quot;path&quot;:&quot;archives&#x2F;57744bfb.html&quot;,&quot;title&quot;:&quot;爬虫笔记六 -- 异步爬虫&quot;}</script><script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script><title>爬虫笔记六 -- 异步爬虫 | Hyacinthの博客</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="alternate" href="/atom.xml" title="Hyacinthの博客" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Hyacinthの博客</h1><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">记录点滴日常</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">协程的基本原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#aiohttp-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">aiohttp 的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E6%88%98"><span class="nav-number">3.</span> <span class="nav-text">实战</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Hyacinth" src="/images/rotate.gif"><p class="site-author-name" itemprop="name">Hyacinth</p><div class="site-description" itemprop="description">平常心 普通人</div></div><div class="site-state-wrap site-overview-item animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">56</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">13</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author site-overview-item animated"><span class="links-of-author-item"><a href="https://github.com/SpeedPromise" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SpeedPromise" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:teemopro@163.com" title="E-Mail → mailto:teemopro@163.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div><canvas id="canvas" style="width:60%">当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>!function(){var o,a,r,f,t,i=[[[0,0,1,1,1,0,0],[0,1,1,0,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,0,1,1,0],[0,0,1,1,1,0,0]],[[0,0,0,1,1,0,0],[0,1,1,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[1,1,1,1,1,1,1]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,0,0,1,1],[1,1,1,1,1,1,1]],[[1,1,1,1,1,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,0,1,1,1,0],[0,0,1,1,1,1,0],[0,1,1,0,1,1,0],[1,1,0,0,1,1,0],[1,1,1,1,1,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,1,1]],[[1,1,1,1,1,1,1],[1,1,0,0,0,0,0],[1,1,0,0,0,0,0],[1,1,1,1,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[1,1,1,1,1,1,1],[1,1,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,1,1,0,0,0,0]],[[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0]]],e=document.getElementById("canvas");function h(t,e){for(var n=[1,2,3],l=["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"],o=0;o<i[e].length;o++)for(var a,h=0;h<i[e][o].length;h++)1==i[e][o][h]&&(a={x:14*(f+2)*t+2*h*(f+1)+(f+1),y:2*o*(f+1)+(f+1),stepX:Math.floor(4*Math.random()-2),stepY:-2*n[Math.floor(Math.random()*n.length)],color:l[Math.floor(Math.random()*l.length)],disY:1},r.push(a))}function n(){e.height=100;for(var t=0;t<a.length;t++)!function(t,e){for(var n=0;n<i[e].length;n++)for(var l=0;l<i[e][n].length;l++)1==i[e][n][l]&&(o.beginPath(),o.arc(14*(f+2)*t+2*l*(f+1)+(f+1),2*n*(f+1)+(f+1),f,0,2*Math.PI),o.closePath(),o.fill())}(t,a[t]);for(t=0;t<r.length;t++)o.beginPath(),o.arc(r[t].x,r[t].y,f,0,2*Math.PI),o.fillStyle=r[t].color,o.closePath(),o.fill()}e.getContext&&(o=e.getContext("2d"),e.height=100,e.width=700,o.fillStyle="#f00",o.fillRect(10,10,50,50),a=[],r=[],f=e.height/20-1,t=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),a.push(t[1],t[2],10,t[3],t[4],10,t[5],t[6]),clearInterval(void 0),setInterval(function(){!function(){var t=[],e=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),n=[];n.push(e[1],e[2],10,e[3],e[4],10,e[5],e[6]);for(var l=a.length-1;0<=l;l--)n[l]!==a[l]&&t.push(l+"_"+(Number(a[l])+1)%10);for(l=0;l<t.length;l++)h.apply(this,t[l].split("_"));a=n.concat()}(),function(){for(var t=0;t<r.length;t++)r[t].stepY+=r[t].disY,r[t].x+=r[t].stepX,r[t].y+=r[t].stepY,(r[t].x>700+f||r[t].y>100+f)&&(r.splice(t,1),t--)}(),n()},50))}()</script><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-history fa-" aria-hidden="true"></i> 近期文章</div><ul class="links-of-blogroll-list"><li><a href="/archives/aa65c569.html" title="小米刷机" target="_blank">小米刷机</a></li><li><a href="/archives/63270a97.html" title="Electron 安装失败：Electron failed to install correctly" target="_blank">Electron 安装失败：Electron failed to install correctly</a></li><li><a href="/archives/9679350.html" title="Webug 4.0 笔记" target="_blank">Webug 4.0 笔记</a></li><li><a href="/archives/ad504db1.html" title="爬虫笔记十 -- 模拟登录" target="_blank">爬虫笔记十 -- 模拟登录</a></li><li><a href="/archives/a900817c.html" title="爬虫笔记九 -- 代理池的搭建及实战应用" target="_blank">爬虫笔记九 -- 代理池的搭建及实战应用</a></li></ul></div><div id="music163player"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="280" height="52" src="//music.163.com/outchain/player?type=2&id=1808492017&auto=0&height=32"></iframe></div></div></div></div></aside><div class="sidebar-dimmer"></div></header><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a href="https://github.com/SpeedPromise" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://speedpromise.github.io/archives/57744bfb.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/rotate.gif"><meta itemprop="name" content="Hyacinth"><meta itemprop="description" content="平常心 普通人"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hyacinthの博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">爬虫笔记六 -- 异步爬虫</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-02-22 20:09:20" itemprop="dateCreated datePublished" datetime="2022-02-22T20:09:20+08:00">2022-02-22</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a> </span></span><span id="/archives/57744bfb.html" class="post-meta-item leancloud_visitors" data-flag-title="爬虫笔记六 -- 异步爬虫" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span></div><div class="post-meta"><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>7.4k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/AdlUeT3QpzktrEh.png"></p><p>爬虫是 IO 密集型任务，当使用 requests 库爬虫某个站点，发出请求后必须等待网站返回响应，才能继续运行，那有没有可以优化的方案呢？本章来了解一下异步爬虫的概念。</p><span id="more"></span><p>先看一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s : %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">TOTAL = <span class="number">5</span></span><br><span class="line">URL = <span class="string">&#x27;https://www.httpbin.org/delay/5&#x27;</span></span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL + <span class="number">1</span>):</span><br><span class="line">    logging.info(<span class="string">&#x27;crawling %s&#x27;</span>, URL)</span><br><span class="line">    response = requests.get(URL)</span><br><span class="line">end_time = time.time()</span><br><span class="line">logging.info(<span class="string">&#x27;total time %s seconds&#x27;</span>, end_time - start_time)</span><br></pre></td></tr></table></figure><p>需要的时间是 50 多秒，每个页面都需要等待 5 秒才能加载出来，严重拖慢爬取速度。对于这种 IO 密集型任务，使用协程就十分高效。</p><h3 id="协程的基本原理"><a href="#协程的基本原理" class="headerlink" title="协程的基本原理"></a>协程的基本原理</h3><p>协程(coroutine)，又称微线程、纤程，是一种运行在用户态的轻量级线程。</p><p>协程拥有自己的寄存器上下文和栈。协程在调度切换时，将寄存器上下文和栈保存到其他地方，等切回来的时候，再恢复先前保存的寄存器上下文和栈。因此，协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入，就相当于进入上一次调用的状态。</p><p>我们可以用协程来实现异步操作，在网络爬虫场景中，发出请求后需要等待一定时间才能得到响应，可以利用协程去干其他事情，等得到响应后再切回来继续处理。Python 中使用协程最常用的库莫过于 asyncio。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">x</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;Number&#x27;</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">coroutine = execute(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Coroutine&#x27;</span>, coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling execute&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(coroutine)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br><span class="line"></span><br><span class="line">------------- result -------------</span><br><span class="line">Coroutine &lt;coroutine <span class="built_in">object</span> execute at <span class="number">0x0000016376D324C0</span>&gt;</span><br><span class="line">After calling execute</span><br><span class="line">Number <span class="number">1</span></span><br><span class="line">After calling loop</span><br></pre></td></tr></table></figure><p>这里用 <code>async</code> 定义了 <code>execute</code> 方法，调用后并没有直接执行，返回了一个 coroutine 协程对象。之后使用了一个 <code>get_event_loop</code>方法创建了一个事件循环 loop，并调用了 <code>run_until_complete</code>方法将协程对象注册到事件循环中，接着启动。</p><p>task：任务，是对协程对象的进一步封装，比协程对象多了运行状态，如 running、finished 等，可以利用这些状态获取协程对象的执行情况。</p><p>上面代码实际也是将 coroutine 封装成了 task 对象，我们也可以显式声明：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">task = loop.create_task(coroutine)</span><br><span class="line"><span class="comment"># task = loop_ensure_future(coroutine)  # 另一种定义方法</span></span><br><span class="line">print(<span class="string">&#x27;Task&#x27;</span>, task)</span><br><span class="line">loop.run_until_complete(task)</span><br><span class="line">print(<span class="string">&#x27;After calling loop&#x27;</span>)</span><br><span class="line"></span><br><span class="line">------------- result -------------</span><br><span class="line">Task &lt;Task pending name=<span class="string">&#x27;Task-1&#x27;</span> coro=&lt;execute() running at C:/Users/Pro/Desktop/Web Crawler Notes/test.py:<span class="number">4</span>&gt;&gt;</span><br><span class="line">Number <span class="number">1</span></span><br><span class="line">Task &lt;Task finished name=<span class="string">&#x27;Task-1&#x27;</span> coro=&lt;execute() done, defined at C:/Users/Pro/Desktop/Web Crawler Notes/test.py:<span class="number">4</span>&gt; result=<span class="literal">None</span>&gt;</span><br><span class="line">After calling loop</span><br></pre></td></tr></table></figure><p>可以看到 task 对象创建时是 pending 状态，等加到事件循环中执行后就成了 finished 状态。</p><p>task 运行完毕后可以调用 result() 方法获取运行结果，也可以绑定回调方法来获取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">task</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;Status:&#x27;</span>, task.result())</span><br><span class="line">    </span><br><span class="line">task.add_done_callback(callback)</span><br></pre></td></tr></table></figure><p>如果想要执行多次请求，可以这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">request</span>(<span class="params">x</span>):</span></span><br><span class="line">    url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">    status = requests.get(url)</span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">    print(<span class="string">&#x27;Task result:&#x27;</span>, task.result())</span><br></pre></td></tr></table></figure><p>再回到开头的例子，这里还需要用到 aiohttp 这个异步请求库，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">url</span>):</span></span><br><span class="line">    session = aiohttp.ClientSession()</span><br><span class="line">    response = <span class="keyword">await</span> session.get(url)</span><br><span class="line">    <span class="keyword">await</span> response.text()</span><br><span class="line">    <span class="keyword">await</span> session.close()</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">request</span>():</span></span><br><span class="line">    url = <span class="string">&#x27;https://www.httpbin.org/delay/5&#x27;</span></span><br><span class="line">    print(<span class="string">&#x27;Watting for&#x27;</span>, url)</span><br><span class="line">    response = <span class="keyword">await</span> get(url)</span><br><span class="line">    print(<span class="string">&#x27;Get response from&#x27;</span>, url, <span class="string">&#x27;response&#x27;</span>, response)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tasks = [asyncio.ensure_future(request()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">&#x27;Cost time&#x27;</span>, end - start)</span><br></pre></td></tr></table></figure><p>耗时时间缩到了个位数。</p><p>await 关键词可以将当前协程挂起，转而执行其他协程，运行时几乎同时所有 task 同时挂起，等到几秒后又是几乎同时返回响应，这就是异步操作的高效之处。</p><h3 id="aiohttp-的使用"><a href="#aiohttp-的使用" class="headerlink" title="aiohttp 的使用"></a>aiohttp 的使用</h3><p>asyncio 模块的内部实现了对 TCP、UDP、SSL 协议的异步操作，但没有 HTTP，而 aiohttp 是基于 asyncio 的异步 HTTP 网络模块，它既提供了服务端，也提供了客户端</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">session, url</span>):</span></span><br><span class="line">    <span class="comment"># session.get() 可以添加 params</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> response.text(), response.status</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        html, status = <span class="keyword">await</span> fetch(session, <span class="string">&#x27;https://cuiqingcai.com&#x27;</span>)</span><br><span class="line">        print(<span class="string">f&#x27;html, <span class="subst">&#123;html[:<span class="number">100</span>]&#125;</span>...&#x27;</span>)</span><br><span class="line">        print(<span class="string">f&#x27;status: <span class="subst">&#123;status&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(main())</span><br></pre></td></tr></table></figure><p>每个异步方法前面都要加上 async 来修饰，包括 with as 语句，在 Python 中，with as 语句用于声明一个上下文管理器，能够帮我们自动分配和释放资源。对于一些返回协程对象的操作，前面需要加 await 修饰。</p><p>aiohttp 也支持其他请求类型，如 POST、PUT、DELETE 等，进行 POST 请求时，不同请求参数支持不同类型的请求内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session.post(url, data=data)  <span class="string">&quot;Content-Type&quot;</span>=<span class="string">&quot;application/x-www-form-urlencoded&quot;</span></span><br><span class="line">session.post(url, json=data)  <span class="string">&quot;Content-Type&quot;</span>=<span class="string">&quot;application/json&quot;</span></span><br></pre></td></tr></table></figure><p>超时设置(秒)，异常抛出为 <code>asyncio.TimeoutError</code> 类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tiemout = aiohttp.ClinetTimeout(total=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(timeout=timeout) <span class="keyword">as</span> session:</span><br></pre></td></tr></table></figure><p>并发限制，考虑到目标网站的负载程度，可以借助 asyncio 的 <code>Semaphore</code> 来控制并发量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CONCURRENCY = <span class="number">5</span></span><br><span class="line">semaphore = asyncio.Semaphore(CONCURRENCY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">crawl_api</span>():</span></span><br><span class="line">	<span class="keyword">async</span> <span class="keyword">with</span> semaphore:</span><br><span class="line">		<span class="keyword">async</span> <span class="keyword">with</span> session.get(URL) <span class="keyword">as</span> renponse: </span><br></pre></td></tr></table></figure><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>爬取一个<a target="_blank" rel="noopener external nofollow noreferrer" href="https://spa5.scrape.center/">图书网站</a>，这里我们要实现 MongoDB 的异步存储，还需要用到 motor 库。</p><p>初步分析：本站也是采用列表页和详情页的结构，加载方式是 Ajax，分页的 Ajax 请求接口格式为：<code>https://spa5.scrape.center/api/book/?limit=18&amp;offset=0</code>，offset 是每一页偏移量，limit 固定为 18，即每页书籍数量，且返回的列表页书籍中带有书籍的 id，可以据此访问书籍详情页，详情页接口格式为:<code>https://spa5.scrape.center/detail/&#123;id&#125;</code></p><p><img data-src="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/nwZdlBrSsU58hJi.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> aiohttp <span class="keyword">import</span> ContentTypeError</span><br><span class="line"><span class="keyword">from</span> motor.motor_asyncio <span class="keyword">import</span> AsyncIOMotorClient</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://spa5.scrape.center/api/book/?limit=&#123;limit&#125;&amp;offset=&#123;offset&#125;&#x27;</span></span><br><span class="line">DETAIL_URL = <span class="string">&#x27;https://spa5.scrape.center/api/book/&#123;id&#125;&#x27;</span></span><br><span class="line">PAGE_SIZE = <span class="number">18</span></span><br><span class="line">PAGE_NUMBER = <span class="number">1</span></span><br><span class="line">CONCURRENCY = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">MONGO_CONNECTION = <span class="string">&#x27;mongodb://localhost:27017&#x27;</span></span><br><span class="line">MONGO_DB = <span class="string">&#x27;books&#x27;</span></span><br><span class="line">MONGO_COLLECTION = <span class="string">&#x27;books&#x27;</span></span><br><span class="line"></span><br><span class="line">client = AsyncIOMotorClient(MONGO_CONNECTION)</span><br><span class="line">db = client[MONGO_DB]</span><br><span class="line">collection = db[MONGO_COLLECTION]</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.semaphore = asyncio.Semaphore(CONCURRENCY)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">crawl_api</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> self.semaphore:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                logging.info(<span class="string">&#x27;crawling: %s&#x27;</span>, url)</span><br><span class="line">                <span class="keyword">async</span> <span class="keyword">with</span> self.session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">                    <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">await</span> response.json()</span><br><span class="line">            <span class="keyword">except</span> ContentTypeError <span class="keyword">as</span> e:</span><br><span class="line">                logging.error(<span class="string">&#x27;error occurred while crawling %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">crawl_index</span>(<span class="params">self, page</span>):</span></span><br><span class="line">        url = INDEX_URL.<span class="built_in">format</span>(limit=PAGE_SIZE, offset=PAGE_SIZE * (page - <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> self.crawl_api(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">crawl_detail</span>(<span class="params">self, <span class="built_in">id</span></span>):</span></span><br><span class="line">        print(<span class="string">&#x27;id&#x27;</span>, <span class="built_in">id</span>)</span><br><span class="line">        url = DETAIL_URL.<span class="built_in">format</span>(<span class="built_in">id</span>=<span class="built_in">id</span>)</span><br><span class="line">        data = <span class="keyword">await</span> self.crawl_api(url)</span><br><span class="line">        <span class="keyword">await</span> self.save_data(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        logging.info(<span class="string">&#x27;saving data %s&#x27;</span>, data.get(<span class="string">&#x27;name&#x27;</span>))</span><br><span class="line">        <span class="keyword">if</span> data:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">await</span> collection.update_one(&#123;</span><br><span class="line">                <span class="string">&#x27;id&#x27;</span>: data.get(<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                <span class="string">&#x27;$set&#x27;</span>: data</span><br><span class="line">            &#125;, upsert=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.session = aiohttp.ClientSession()</span><br><span class="line">        crawl_index_tasks = [asyncio.ensure_future(self.crawl_index(page)) <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, PAGE_NUMBER + <span class="number">1</span>)]</span><br><span class="line">     	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        gather 和 wait 区别：</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        wait(tasks) 使用一个set保存它创建的Task实例。因为set是无序的所以任务不会顺序执行。</span></span><br><span class="line"><span class="string">        wait的返回值是一个元组，包括两个集合，分别表示已完成和未完成的任务。wait第二个参数为一个超时值。</span></span><br><span class="line"><span class="string">        达到这个超时时间后，未完成的任务状态变为pending，当程序退出时还有任务没有完成此时就会看到错误提示。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        gather(*tasks) 和 wait 不同的是。 1.gather任务无法取消；2.返回值是一个结果列表；3.可以按照传入参数的顺序，顺序输出。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        results = <span class="keyword">await</span> asyncio.gather(*crawl_index_tasks)</span><br><span class="line">        print(<span class="string">&#x27;results:&#x27;</span>, results)</span><br><span class="line">        ids = []</span><br><span class="line">        <span class="keyword">for</span> index_data <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> index_data:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> index_data.get(<span class="string">&#x27;results&#x27;</span>):</span><br><span class="line">                ids.append(item.get(<span class="string">&#x27;id&#x27;</span>))</span><br><span class="line">        crawl_detail_tasks = [asyncio.ensure_future(self.crawl_detail(<span class="built_in">id</span>)) <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> ids]</span><br><span class="line">        <span class="keyword">await</span> asyncio.wait(crawl_detail_tasks)</span><br><span class="line">        <span class="keyword">await</span> self.session.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spider = Spider()</span><br><span class="line">    loop.run_until_complete(spider.main())</span><br></pre></td></tr></table></figure><p>爬取过程如下：</p><p><img data-src="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/Hw7Vxz16nWrBYFX.png"></p><p>可以看到书籍都存到了 MongoDB 中：</p><img data-src="https://hyacinth-blog.oss-cn-guangzhou.aliyuncs.com/img/52dkJOrNYMIfaDn.png" alt="" style="zoom:80%"></div><div class="popular-posts-header">推荐阅读</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\fc84b201.html" rel="bookmark">爬虫笔记一 -- 爬虫基础</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\50c99347.html" rel="bookmark">爬虫笔记二 -- 基本库的使用</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\79659fc4.html" rel="bookmark">爬虫笔记三 -- 解析库的使用</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\e6a92538.html" rel="bookmark">Python 批量重命名文件</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\4ca1a587.html" rel="bookmark">爬虫笔记五 -- Ajax 数据爬取</a></div></li></ul><footer class="post-footer"><div class="reward-container"><div>Buy me a coffee</div><button onclick='document.querySelector(".post-reward").classList.toggle("active")'>赞赏</button><div class="post-reward"><div><img src="/images/wechat-pay.png" alt="Hyacinth 微信"> <span>微信</span></div><div><img src="/images/alipay-pay.png" alt="Hyacinth 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Hyacinth</li><li><strong>修改时间：</strong> <time title="修改时间：2022-03-28 12:41:38" itemprop="dateModified" datetime="2022-03-28T12:41:38+08:00">2022/03/28</time></li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://speedpromise.github.io/archives/57744bfb.html" title="爬虫笔记六 -- 异步爬虫">https://speedpromise.github.io/archives/57744bfb.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/images/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i> </span><span class="label">WeChat</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-tags"><a href="/tags/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/" rel="tag"><i class="fa fa-tag"></i> 爬虫笔记</a></div><div class="post-nav"><div class="post-nav-item"><a href="/archives/4ca1a587.html" rel="prev" title="爬虫笔记五 -- Ajax 数据爬取"><i class="fa fa-chevron-left"></i> 爬虫笔记五 -- Ajax 数据爬取</a></div><div class="post-nav-item"><a href="/archives/d1c41f0f.html" rel="next" title="爬虫笔记七 -- JavaScript 动态渲染页面爬取">爬虫笔记七 -- JavaScript 动态渲染页面爬取 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments gitalk-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Hyacinth</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">291k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">4:24</span></span></div></div></footer><script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>// 代码折叠<script src="/js/code-unfold.js"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="leancloud_visitors" type="application/json">{&quot;enable&quot;:true,&quot;app_id&quot;:&quot;mXCXRvyDJTe1MizGNz8MBQCC-MdYXbMMI&quot;,&quot;app_key&quot;:&quot;NKjSKtz16WlOVxKDRa1tJNgl&quot;,&quot;server_url&quot;:null,&quot;security&quot;:false}</script><script src="/js/third-party/statistics/lean-analytics.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;,&quot;integrity&quot;:&quot;sha256-ncNI9OXOS5Ek4tzVYiOMmN&#x2F;KKCPZ6V0Cpv2P&#x2F;zHntiA&#x3D;&quot;}}</script><script src="/js/third-party/math/mathjax.js"></script><script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script><script>var options={bottom:"64px",right:"unset",left:"32px",time:"0.5s",mixColor:"transparent",backgroundColor:"transparent",buttonColorDark:"#100f2c",buttonColorLight:"#fff",saveInCookies:!0,label:"🌓",autoMatchOsTheme:!0};const darkmode=new Darkmode(options);window.darkmode=darkmode,darkmode.showWidget()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous"><script class="next-config" data-name="gitalk" type="application/json">{&quot;enable&quot;:true,&quot;github_id&quot;:&quot;SpeedPromise&quot;,&quot;repo&quot;:&quot;blog-comments&quot;,&quot;client_id&quot;:&quot;c87c14d15109ca258c8c&quot;,&quot;client_secret&quot;:&quot;fcb23a076c153b6a22f7dc957f54510992dc0342&quot;,&quot;admin_user&quot;:&quot;SpeedPromise&quot;,&quot;distraction_free_mode&quot;:true,&quot;proxy&quot;:&quot;https:&#x2F;&#x2F;cors-anywhere.azm.workers.dev&#x2F;https:&#x2F;&#x2F;github.com&#x2F;login&#x2F;oauth&#x2F;access_token&quot;,&quot;language&quot;:null,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;gitalk@1.7.2&#x2F;dist&#x2F;gitalk.min.js&quot;,&quot;integrity&quot;:&quot;sha256-Pmj85ojLaPOWwRtlMJwmezB&#x2F;Qg8BzvJp5eTzvXaYAfA&#x3D;&quot;},&quot;path_md5&quot;:&quot;b441bfd1fa0ea6c098295d858408dc9f&quot;}</script><script src="/js/third-party/comments/gitalk.js"></script><script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script async src="/js/cursor/fireworks.js"></script></body></html>