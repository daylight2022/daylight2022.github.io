<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;hyacinth.fit&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:true,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:true,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;buttons&quot;,&quot;active&quot;:&quot;gitalk&quot;,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null,&quot;activeClass&quot;:&quot;gitalk&quot;},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:true}}</script><script src="/js/config.js"></script><meta name="description" content="有些场景，比如 Ajax 接口中有加密参数或是像 ECharts 这种经过 Js 计算生成的页面，很难去爬取和分析规律，本章我们来了解一种技术，归纳为“所见即所爬”，我们可以直接模拟浏览器运行，然后爬取数据。"><meta property="og:type" content="article"><meta property="og:title" content="爬虫笔记七 -- JavaScript 动态渲染页面爬取"><meta property="og:url" content="https://hyacinth.fit/archives/d1c41f0f.html"><meta property="og:site_name" content="Hyacinthの博客"><meta property="og:description" content="有些场景，比如 Ajax 接口中有加密参数或是像 ECharts 这种经过 Js 计算生成的页面，很难去爬取和分析规律，本章我们来了解一种技术，归纳为“所见即所爬”，我们可以直接模拟浏览器运行，然后爬取数据。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://s2.loli.net/2022/02/15/MUcb8kYIRaP21gN.png"><meta property="og:image" content="https://s2.loli.net/2022/02/24/dkVPhOTw6xyJ8RN.png"><meta property="og:image" content="https://s2.loli.net/2022/02/25/RLk7uOWFAdp3gt4.png"><meta property="og:image" content="https://s2.loli.net/2022/02/28/wHSbBJF3mfKsVyN.png"><meta property="og:image" content="https://s2.loli.net/2022/02/28/oAzHShjb9e46kDQ.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/F6GtieuvQAd5YOJ.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/xeHsFJqp3Mblwor.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/pAh9bFIc7sYV81B.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/JyuxIQwUtGKdMel.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/6YPXBhzTH71Fpwo.png"><meta property="og:image" content="https://s2.loli.net/2022/03/01/x1Ty6G8ZisWg245.png"><meta property="article:published_time" content="2022-02-24T12:25:08.000Z"><meta property="article:modified_time" content="2022-03-01T07:56:25.783Z"><meta property="article:author" content="Hyacinth"><meta property="article:tag" content="爬虫笔记"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://s2.loli.net/2022/02/15/MUcb8kYIRaP21gN.png"><link rel="canonical" href="https://hyacinth.fit/archives/d1c41f0f.html"><script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;hyacinth.fit&#x2F;archives&#x2F;d1c41f0f.html&quot;,&quot;path&quot;:&quot;archives&#x2F;d1c41f0f.html&quot;,&quot;title&quot;:&quot;爬虫笔记七 -- JavaScript 动态渲染页面爬取&quot;}</script><script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script><title>爬虫笔记七 -- JavaScript 动态渲染页面爬取 | Hyacinthの博客</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="alternate" href="/atom.xml" title="Hyacinthの博客" type="application/atom+xml"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Hyacinthの博客</h1><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">记录点滴日常</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Selenium-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.</span> <span class="nav-text">Selenium 的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Splash-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">Splash 的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pyppeteer-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">Pyppeteer 的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Playwright-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">4.</span> <span class="nav-text">Playwright 的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CSS-%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB%E5%8F%8D%E7%88%AC%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%8E%E7%88%AC%E5%8F%96%E5%AE%9E%E6%88%98"><span class="nav-number">5.</span> <span class="nav-text">CSS 位置偏移反爬案例分析与爬取实战</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%97%E4%BD%93%E5%8F%8D%E7%88%AC%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%8E%E7%88%AC%E5%8F%96%E5%AE%9E%E6%88%98"><span class="nav-number">6.</span> <span class="nav-text">字体反爬案例分析与爬取实战</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Hyacinth" src="/images/rotate.gif"><p class="site-author-name" itemprop="name">Hyacinth</p><div class="site-description" itemprop="description">平常心 普通人</div></div><div class="site-state-wrap site-overview-item animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">51</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">6</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author site-overview-item animated"><span class="links-of-author-item"><a href="https://github.com/SpeedPromise" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SpeedPromise" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:teemopro@163.com" title="E-Mail → mailto:teemopro@163.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div><canvas id="canvas" style="width:60%">当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>!function(){var o,a,r,f,t,i=[[[0,0,1,1,1,0,0],[0,1,1,0,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,0,1,1,0],[0,0,1,1,1,0,0]],[[0,0,0,1,1,0,0],[0,1,1,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[1,1,1,1,1,1,1]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,0,0,1,1],[1,1,1,1,1,1,1]],[[1,1,1,1,1,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,0,1,1,1,0],[0,0,1,1,1,1,0],[0,1,1,0,1,1,0],[1,1,0,0,1,1,0],[1,1,1,1,1,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,1,1]],[[1,1,1,1,1,1,1],[1,1,0,0,0,0,0],[1,1,0,0,0,0,0],[1,1,1,1,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[1,1,1,1,1,1,1],[1,1,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,1,1,0,0,0,0]],[[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0]]],e=document.getElementById("canvas");function h(t,e){for(var n=[1,2,3],l=["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"],o=0;o<i[e].length;o++)for(var a,h=0;h<i[e][o].length;h++)1==i[e][o][h]&&(a={x:14*(f+2)*t+2*h*(f+1)+(f+1),y:2*o*(f+1)+(f+1),stepX:Math.floor(4*Math.random()-2),stepY:-2*n[Math.floor(Math.random()*n.length)],color:l[Math.floor(Math.random()*l.length)],disY:1},r.push(a))}function n(){e.height=100;for(var t=0;t<a.length;t++)!function(t,e){for(var n=0;n<i[e].length;n++)for(var l=0;l<i[e][n].length;l++)1==i[e][n][l]&&(o.beginPath(),o.arc(14*(f+2)*t+2*l*(f+1)+(f+1),2*n*(f+1)+(f+1),f,0,2*Math.PI),o.closePath(),o.fill())}(t,a[t]);for(t=0;t<r.length;t++)o.beginPath(),o.arc(r[t].x,r[t].y,f,0,2*Math.PI),o.fillStyle=r[t].color,o.closePath(),o.fill()}e.getContext&&(o=e.getContext("2d"),e.height=100,e.width=700,o.fillStyle="#f00",o.fillRect(10,10,50,50),a=[],r=[],f=e.height/20-1,t=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),a.push(t[1],t[2],10,t[3],t[4],10,t[5],t[6]),clearInterval(void 0),setInterval(function(){!function(){var t=[],e=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),n=[];n.push(e[1],e[2],10,e[3],e[4],10,e[5],e[6]);for(var l=a.length-1;0<=l;l--)n[l]!==a[l]&&t.push(l+"_"+(Number(a[l])+1)%10);for(l=0;l<t.length;l++)h.apply(this,t[l].split("_"));a=n.concat()}(),function(){for(var t=0;t<r.length;t++)r[t].stepY+=r[t].disY,r[t].x+=r[t].stepX,r[t].y+=r[t].stepY,(r[t].x>700+f||r[t].y>100+f)&&(r.splice(t,1),t--)}(),n()},50))}()</script><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-history fa-" aria-hidden="true"></i> 近期文章</div><ul class="links-of-blogroll-list"><li><a href="/archives/d1c41f0f.html" title="爬虫笔记七 -- JavaScript 动态渲染页面爬取" target="_blank">爬虫笔记七 -- JavaScript 动态渲染页面爬取</a></li><li><a href="/archives/57744bfb.html" title="爬虫笔记六 -- 异步爬虫" target="_blank">爬虫笔记六 -- 异步爬虫</a></li><li><a href="/archives/4ca1a587.html" title="爬虫笔记五 -- Ajax 数据爬取" target="_blank">爬虫笔记五 -- Ajax 数据爬取</a></li><li><a href="/archives/39ed07bf.html" title="爬虫笔记四 -- 数据的存储" target="_blank">爬虫笔记四 -- 数据的存储</a></li><li><a href="/archives/79659fc4.html" title="爬虫笔记三 -- 解析库的使用" target="_blank">爬虫笔记三 -- 解析库的使用</a></li></ul></div><div id="music163player"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="280" height="52" src="//music.163.com/outchain/player?type=2&id=1808492017&auto=0&height=32"></iframe></div></div></div></div></aside><div class="sidebar-dimmer"></div></header><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a href="https://github.com/SpeedPromise" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://hyacinth.fit/archives/d1c41f0f.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/rotate.gif"><meta itemprop="name" content="Hyacinth"><meta itemprop="description" content="平常心 普通人"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hyacinthの博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">爬虫笔记七 -- JavaScript 动态渲染页面爬取</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-02-24 20:25:08" itemprop="dateCreated datePublished" datetime="2022-02-24T20:25:08+08:00">2022-02-24</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a> </span></span><span id="/archives/d1c41f0f.html" class="post-meta-item leancloud_visitors" data-flag-title="爬虫笔记七 -- JavaScript 动态渲染页面爬取" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span></div><div class="post-meta"><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>26k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>24 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><img data-src="https://s2.loli.net/2022/02/15/MUcb8kYIRaP21gN.png" style="zoom:67%"><p>有些场景，比如 Ajax 接口中有加密参数或是像 ECharts 这种经过 Js 计算生成的页面，很难去爬取和分析规律，本章我们来了解一种技术，归纳为“所见即所爬”，我们可以直接模拟浏览器运行，然后爬取数据。</p><span id="more"></span><h3 id="Selenium-的使用"><a href="#Selenium-的使用" class="headerlink" title="Selenium 的使用"></a>Selenium 的使用</h3><p>现在很多网站的 Ajax 请求的接口都含有加密参数，例如 token、sign 等，<a target="_blank" rel="noopener external nofollow noreferrer" href="https://spa2.scrape.center/">示例网址</a>的 Ajax 接口就含有一个 token 参数，如下图：</p><p><img data-src="https://s2.loli.net/2022/02/24/dkVPhOTw6xyJ8RN.png"></p><p>如果不深入分析找到 token 的构造逻辑是难以直接模拟 Ajax 请求的，除此之外，也可以使用模拟浏览器运行的方式来爬取数据，我们先来了解一下 Selenium 自动化测试工具的基本用法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()  <span class="comment"># 初始化浏览器对象</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.get(<span class="string">&#x27;https://baidu.com&#x27;</span>)  <span class="comment"># 访问页面</span></span><br><span class="line">    <span class="comment"># 查找单个节点，复数为查找多个，查找方式有 ID、NAME、XPATH、TAG_NAME、CLASS_NAME、CSS_SELECTOR 等</span></span><br><span class="line">    <span class="built_in">input</span> = browser.find_element(By.ID, <span class="string">&#x27;kw&#x27;</span>)  </span><br><span class="line">    <span class="comment"># send_keys() 输入文字、clear() 清空文字、click() 点击按钮</span></span><br><span class="line">    <span class="built_in">input</span>.send_keys(<span class="string">&#x27;Python&#x27;</span>)</span><br><span class="line">    <span class="built_in">input</span>.send_keys(Keys.ENTER)</span><br><span class="line">    wait = WebDriverWait(browser, <span class="number">10</span>)</span><br><span class="line">    wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;content-left&#x27;</span>)))</span><br><span class="line">    print(browser.current_url)</span><br><span class="line">    print(browser.get_cookies())</span><br><span class="line">    print(browser.page_source)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure><p>要实现鼠标拖拽、键盘按键等，需要使用<strong>动作链</strong>，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line">browser.switch_to.frame(<span class="string">&#x27;iframeResult&#x27;</span>)  <span class="comment"># 切换到子 frame，在父 frame 也是无法获取子 frame 信息的</span></span><br><span class="line">source = browser.find_element(By.CSS_SELECTOR, <span class="string">&#x27;#draggable&#x27;</span>)</span><br><span class="line">target = browser.find_element(By.CSS_SELECTOR, <span class="string">&#x27;#droppable&#x27;</span>)</span><br><span class="line">actions = ActionChains(browser)</span><br><span class="line">actions.drag_and_drop(source, target)</span><br><span class="line">actions.perform()</span><br></pre></td></tr></table></figure><p>Selenium 支持模拟运行 JavaScript，帮助实现比如下拉进度条等操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>)</span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.scrollTo(0, document.body.scrollHeight)&#x27;</span>)</span><br><span class="line">browser.execute_script(<span class="string">&#x27;alert(&quot;To Bottom&quot;)&#x27;</span>)</span><br></pre></td></tr></table></figure><p>Selenium 提供了选择节点的方法，也提供了相关的方法和属性来直接提取节点属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">node = browser.find_element(By.ID, <span class="string">&#x27;kw&#x27;</span>)</span><br><span class="line">attr = node.get_attritube(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">text = node.text</span><br><span class="line">id_ = node.<span class="built_in">id</span></span><br><span class="line">location = node.location  <span class="comment"># 节点在页面中的相对位置</span></span><br><span class="line">tag_name = node.tag_name  <span class="comment"># 标签名称</span></span><br><span class="line">size = node.size  <span class="comment"># 节点大小，即宽高</span></span><br></pre></td></tr></table></figure><p>延迟等待</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 隐式等待，固定等待时间</span></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser = implicitly_wait(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显式等待，指定最长等待时间</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">wait = WebDriverWait(browser, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 调用 wait.until() 传入等待条件</span></span><br><span class="line">input_ = wait.until(EC.presence_of_element_located((By.ID, <span class="string">&#x27;q&#x27;</span>)))</span><br></pre></td></tr></table></figure><p>更多等待条件可以参考<a target="_blank" rel="noopener external nofollow noreferrer" href="https://selenium-python.readthedocs.io/api.html?highlight=expected_con#module-selenium.webdriver.support.expected_conditions">官方文档</a>。</p><p>前进和后退</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">browser.back()</span><br><span class="line">browser.forward()</span><br></pre></td></tr></table></figure><p>Selenium 也可以对 Cookie 进行操作，例如获取、添加、删除等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>)</span><br><span class="line">print(browser.get_cookies())</span><br><span class="line">browser.add_cookie(&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;www.zhihu.com&#x27;</span>, <span class="string">&#x27;value&#x27;</span>: <span class="string">&#x27;geermey&#x27;</span>&#125;)</span><br><span class="line">print(browser.get_cookies())</span><br><span class="line">browser.delete_all_cookies()</span><br><span class="line">print(browser.get_cookies())</span><br></pre></td></tr></table></figure><p>选项卡管理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line">browser.execute_script(<span class="string">&#x27;window.open()&#x27;</span>)</span><br><span class="line">print(browser.window_handles)</span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">1</span>])</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">browser.switch_to.window(browser.window_handles[<span class="number">0</span>])</span><br><span class="line">browser.get(<span class="string">&#x27;https://www.python.org&#x27;</span>)</span><br></pre></td></tr></table></figure><p>异常处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException, NoSuchElementException</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> TimeoutException:</span><br><span class="line">    print(<span class="string">&#x27;Time out&#x27;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser.find_element((By.ID, <span class="string">&#x27;hello&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">    print(<span class="string">&#x27;No Element&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure><p>现在很多网站都增加了对 Selenium 的屏蔽，防止一些爬虫的恶意爬取。大多数情况下，检测的基本原理是检测当前浏览器窗口下的 <code>window.navigator</code> 对象中是否有 <code>webdriver</code> 属性，正常使用时应该是 <code>undefined</code>。另外，执行 JS 语句来置空属性也不行，因为 <code>execute_script</code> 是在页面加载完成后运行的，如下图：</p><p><img data-src="https://s2.loli.net/2022/02/25/RLk7uOWFAdp3gt4.png"></p><p>Selenium 中可以用 CDP(Chrome Devtools Protocol)，利用它可以在页面刚加载的时候执行 JS，执行的 CDP 方法是 <code>Page.addScriptToEvaluateOnNewDocument</code>，另外还可加入几个选项来隐藏 WebDriver 提示条和自动化扩展信息，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-auutomation&#x27;</span>])</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.execute_cdp_cmd(<span class="string">&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;</span>, &#123;</span><br><span class="line">    <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;Object.defineProperty(navigator, &quot;webdriver&quot;, &#123;get: () =&gt; undefined&#125;)&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider1.scrape.center/&#x27;</span>)</span><br></pre></td></tr></table></figure><p>无头模式，网站在运行的时候不会弹窗，减少了干扰，也减少了一些资源（如图片）的加载，在一定程度上节省了资源加载的时间和网络带宽</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_argument(<span class="string">&#x27;--headless&#x27;</span>)  <span class="comment"># 无头模式参数</span></span><br><span class="line">browser = webdriver.Chrome(options=option)</span><br><span class="line">browser.set_window_size(<span class="number">1366</span>, <span class="number">768</span>)  <span class="comment"># 设置窗口大小</span></span><br><span class="line">browser.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line">browser.get_screenshot_as_file(<span class="string">&#x27;preview.png&#x27;</span>)  <span class="comment"># 输出网页截图</span></span><br></pre></td></tr></table></figure><p>来实战爬取开始的示例网站，要完成的主要工作：</p><ul><li>通过 Selenium 遍历网页，获取每部电影的详情页 URL；</li><li>通过 Selenium 爬取每个详情页；</li><li>从详情页获取每部电影的名称、类别、分数、简介、封面等内容；</li><li>数据存储</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://spa2.scrape.center/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIME_OUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">1</span></span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line"></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line"><span class="comment"># 设置无头模式</span></span><br><span class="line">options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">wait = WebDriverWait(browser, TIME_OUT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_page</span>(<span class="params">url, condition, locator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通用爬取方法</span></span><br><span class="line"><span class="string">    :param url: 列表页 URL</span></span><br><span class="line"><span class="string">    :param condition: 页面加载成功的判断条件</span></span><br><span class="line"><span class="string">    :param locator: 定位器，配置查询条件和参数来获得一个或多个节点</span></span><br><span class="line"><span class="string">    :return: WebElement</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        browser.get(url)</span><br><span class="line">        wait.until(condition(locator))</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_index</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    列表页爬取</span></span><br><span class="line"><span class="string">    :param page: 页码</span></span><br><span class="line"><span class="string">    :return: WebElement</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">    scrape_page(url, condition=EC.visibility_of_all_elements_located,</span><br><span class="line">                locator=(By.CSS_SELECTOR, <span class="string">&#x27;#index .item&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_index</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    解析页面</span></span><br><span class="line"><span class="string">    :return: 详情页 URL</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    elements = browser.find_elements(By.CSS_SELECTOR, <span class="string">&#x27;#index .item .name&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> elements:</span><br><span class="line">        href = element.get_attribute(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">        <span class="keyword">yield</span> urljoin(INDEX_URL, href)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_detail</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    详情页爬取</span></span><br><span class="line"><span class="string">    :param url: 详情页 URL</span></span><br><span class="line"><span class="string">    :return: WebElement</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    scrape_page(url, condition=EC.visibility_of_element_located, locator=(By.TAG_NAME, <span class="string">&#x27;h2&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    详情页解析</span></span><br><span class="line"><span class="string">    :return: dict</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    url = browser.current_url</span><br><span class="line">    name = browser.find_element(By.TAG_NAME, <span class="string">&#x27;h2&#x27;</span>).text</span><br><span class="line">    categories = [element.text <span class="keyword">for</span> element <span class="keyword">in</span> browser.find_elements(By.CSS_SELECTOR, <span class="string">&#x27;.categories button span&#x27;</span>)]</span><br><span class="line">    cover = browser.find_element(By.CLASS_NAME, <span class="string">&#x27;cover&#x27;</span>).get_attribute(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    score = browser.find_element(By.CLASS_NAME, <span class="string">&#x27;score&#x27;</span>).text</span><br><span class="line">    drama = browser.find_element(By.CSS_SELECTOR, <span class="string">&#x27;.drama p&#x27;</span>).text</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">        <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">        <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    保存数据</span></span><br><span class="line"><span class="string">    :param data: dict</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">    json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">            scrape_index(page)</span><br><span class="line">            detail_urls = parse_index()</span><br><span class="line">            <span class="comment"># logging.info(&#x27;detail_urls |%s&#x27;, list(detail_urls))</span></span><br><span class="line">            <span class="keyword">for</span> detail_url <span class="keyword">in</span> <span class="built_in">list</span>(detail_urls):</span><br><span class="line">                logging.info(<span class="string">&#x27;get detail url %s&#x27;</span>, detail_url)</span><br><span class="line">                scrape_detail(detail_url)</span><br><span class="line">                detail_data = parse_detail()</span><br><span class="line">                logging.info(<span class="string">&#x27;detail data %s&#x27;</span>, detail_data)</span><br><span class="line">                save_data(detail_data)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="Splash-的使用"><a href="#Splash-的使用" class="headerlink" title="Splash 的使用"></a>Splash 的使用</h3><p>建议通过 Docker 安装，安装命令为：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run <span class="literal">-p</span> <span class="number">8050</span>:<span class="number">8050</span> scrapinghub/splash</span><br><span class="line"><span class="comment"># 加 -d 参数以守护态启动，中断远程服务器连接后不会终止服务运行</span></span><br></pre></td></tr></table></figure><p>启动后在浏览器输入 <code>http://localhost:8050/</code> ，可看到如下页面：</p><img data-src="https://s2.loli.net/2022/02/28/wHSbBJF3mfKsVyN.png" style="zoom:80%"><p>在右上方输入框中输入连接，如<code>https://www.baidu.com</code>，点击<code>Render me!</code>开始渲染。</p><img data-src="https://s2.loli.net/2022/02/28/oAzHShjb9e46kDQ.png" style="zoom:80%"><p>在页面中可以看到脚本代码，是用 Lua 编写的，返回了 html 源代码、页面截图和 HAR 信息。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  <span class="built_in">assert</span>(splash:go(args.url))</span><br><span class="line">  <span class="built_in">assert</span>(splash:wait(<span class="number">0.5</span>))</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    html = splash:html(),</span><br><span class="line">    png = splash:png(),</span><br><span class="line">    har = splash:har(),</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>main 方法中第一个参数为 splash，类似于 Selenium 的 WebDriver，splash 对象的<strong>属性</strong>有：</p><ul><li><strong>args</strong>：用于获取页面加载时配置的参数，支持设置 main 方法的第二个参数为 args；</li><li><strong>js_enabled</strong>：Splash 执行 JS 代码的开关，默认 true；</li><li><strong>resource_timeout</strong>：超时时间，单位秒，设置 0 或 nil 代表不检测超时；</li><li><strong>images_enabled</strong>：设置是否加载图片，默认 true，禁用该属性可节省网络流量提高加载速度，但也因此会影响 DOM 节点的位置，当 JavaScript 对图片节点执行操作时就会收到影响。另外，Splash 会使用缓存，禁用属性后仍会加载出之前的网页图片，重启 Splash 解决；</li><li><strong>plugins_enable</strong>：控制是否开启浏览器插件（Flash 等），默认 false；</li><li><strong>scroll_positon</strong>：控制页面上下左右滚动，如 <code>splash.scroll_positon = &#123;y=400&#125;</code>，表示向下滚动 400 像素。</li></ul><p>splash 对象的<strong>方法</strong>有：</p><ul><li><p><strong>go</strong></p><p><code>ok, reason = splash:go&#123;url, baseurl=nil, headers=nil, http_method=“GET”, body=nil, formdata=nil&#125;</code></p><ul><li>body：http_method 为 POST 时的表单数据，使用的 Content-type 为 application/json；</li><li>formdata：http_method 为 POST 时的表单数据，使用的 Content-type 为 application/x-www-form-urlencoded；</li></ul></li><li><p><strong>wait</strong></p><p><code>ok, reason = splash:wait&#123;time, cancel_on_redirect=false, cancel_on_error=true&#125;</code></p><ul><li>time：等待的时间，单位秒；</li><li>cancel_on_redirect：如果页面重定向则停止等待；</li><li>cancel_on_error：页面加载错误则停止等待。</li></ul></li><li><p><strong>jsfunc</strong></p><p>用于直接调用 JS 方法，需要用双中括号包裹调用的方法，相当于 JS 方法到 Lua 脚本的转变</p><p><code>local git_div_count = splash:jsfunc([[function () &#123;return document.body.getElementsByTagName(&#39;div&#39;);&#125;]])</code></p></li><li><p><strong>evaljs</strong></p><p>用于执行 JS 代码并返回最后一条 JS 语句的返回结果</p><p><code>reslt = splash:evaljs(“document.title”)</code></p></li><li><p><strong>runjs</strong></p><p>与 evaljs 类似，但偏向于执行某些动作或声明某些方法</p><p><code>splash:runjs(&quot;foo = function () &#123;return &#39;bar&#39;&#125;&quot;)</code></p></li><li><p><strong>html</strong></p><p>用于获取网页源代码</p></li><li><p><strong>png/jpeg</strong></p><p>用于获取 PNG/JPEG 格式的网页截图</p></li><li><p><strong>har</strong></p><p>用于获取页面加载过程的描述信息</p></li><li><p><strong>url</strong></p><p>用于获取当前访问的 url</p></li><li><p><strong>set_user_agent</strong></p><p>用于设置浏览器的 User-Agent</p></li><li><p><strong>select/select_all</strong></p><p>用于选中符合条件的第一个节点/所有节点</p></li><li><p><strong>mouse_click</strong></p><p>用于模拟鼠标的点击操作，参数为坐标值 x、y，也可以选中某个节点后直接调用</p></li></ul><p>Splash 提供了一些 HTTP API，结合 Python 使用示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># render.html, render.har </span></span><br><span class="line">url = <span class="string">&#x27;http://localhost:8050/render.html?url=https://www.baidu.com&amp;wait=5&#x27;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line">print(response.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># render.png, render.jpeg</span></span><br><span class="line">url = <span class="string">&#x27;http://localhost:8050/render.png?url=https://www.jd.com/&amp;wait=5&amp;width=1000&amp;height=700&#x27;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;jd.png&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># render.json </span></span><br><span class="line"><span class="comment"># 包含前面所有 render 相关 API，可以通过从传入不同参数控制返回结果，如链接后加上 %html=1%har=1，会返回相应结果</span></span><br><span class="line">url = <span class="string">&#x27;http://localhost:8050/render.json?url=https://www.httpbin.org&#x27;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line">print(response.text)</span><br><span class="line">-------</span><br><span class="line">result&gt;&gt; &#123;<span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.httpbin.org/&quot;</span>, <span class="string">&quot;requestedUrl&quot;</span>: <span class="string">&quot;https://www.httpbin.org/&quot;</span>, <span class="string">&quot;geometry&quot;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1024</span>, <span class="number">768</span>], <span class="string">&quot;title&quot;</span>: <span class="string">&quot;httpbin.org&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># execute 实现与 Lua 脚本对接</span></span><br><span class="line"><span class="comment"># 将 lua 脚本进行 url 编码后拼接到 execute 也可执行相应代码</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line">lua = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">function main(splash, args)</span></span><br><span class="line"><span class="string">    local treat = require(&quot;treat&quot;)</span></span><br><span class="line"><span class="string">    local response = splash:http_get(&quot;http://www.httpbin.org/get&quot;)</span></span><br><span class="line"><span class="string">    return &#123;html=treat.as_string(response.body),</span></span><br><span class="line"><span class="string">        url=response.url,</span></span><br><span class="line"><span class="string">        status=response.status</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://localhost:8050/execute?lua_source=&#x27;</span> + quote(lua)</span><br><span class="line">print(url)</span><br><span class="line">response = requests.get(url)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure><p>用 Splash 爬取页面时，如果数据流非常大，任务非常多，可以考虑搭建一个负载均衡器将压力分散到多个服务器上，减小单个 Splash 服务的压力。</p><p>有了 Splash，可以将 JavaScript 动态渲染的操作完全托管到服务器上，爬虫爬取时不需要依赖 Selenium 等库，业务逻辑会更加轻量级。</p><h3 id="Pyppeteer-的使用"><a href="#Pyppeteer-的使用" class="headerlink" title="Pyppeteer 的使用"></a>Pyppeteer 的使用</h3><p>Selenium 虽然强大，配置较为复杂，需要安装浏览器、驱动，还需安装对应版本的 Python Selenium 库，如果要大规模部署 Selenium 的话，一些环境配置问题也是需要考虑的。由此，我们学习一个 Selenium 的替代品，Pyppeteer，它是 Google 基于 Node.js 开发的一个工具，背后使用了 Chromium 浏览器来进行网页渲染。另外，它是基于 async 实现的，一些操作支持异步方式，相比 Selenium 效率更高。</p><p>安装命令 <code>pip install pyppeteer</code>，安装完后可以执行<code>pyppeteer-install</code>完成一些初始化操作，这会下载一个 Chromium 浏览器并配置好环境变量，不执行则会再第一次运行时自动初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基本使用</span></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    browser = <span class="keyword">await</span> launch()  <span class="comment"># 启动浏览器</span></span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()  <span class="comment"># 新建选项卡</span></span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://spa2.scrape.center/&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> page.waitForSelector(<span class="string">&#x27;.item .name&#x27;</span>)  <span class="comment"># 等待选择器对应节点加载完成</span></span><br><span class="line">    doc = pq(<span class="keyword">await</span> page.content())</span><br><span class="line">    names = [item.text() <span class="keyword">for</span> item <span class="keyword">in</span> doc(<span class="string">&#x27;.item .name&#x27;</span>).items()]</span><br><span class="line">    print(<span class="string">&#x27;Names:&#x27;</span>, names)</span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure><p>详细文档，可查看 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://pyppeteer.github.io/pyppeteer/">Pyppeteer’s documentation</a></p><p>launch 方法详解</p><ul><li>ignoreHTTPSErrors：是否忽略 HTTPS 的错误，默认 False；</li><li>headless：是否启用无头模式，如果 devtools 设为 True，该参数就会设为 False，否则为 True</li><li>executablePath：可执行文件的路径，可指定已存在的 Chrome 或 Chromium，无需使用默认的 Chromium</li><li>slowMo：通过传入指定的时间，可减缓 Pyppeteer 的一些模糊操作</li><li>args(int|str)：执行过程中可传入的额外参数</li><li>ignoreDefaultArgs：是否忽略 Pyppeterer 的默认参数，如果使用，最好设置一些 args，否则可能会有问题</li><li>handleSIGINT：是否响应 SIGINT 信号，即是否可以用 Ctrl + C 终止程序，默认 True</li><li>handleSIGTERM：是否响应 SIGTERM 信号（一般是 kill 命令），默认 True</li><li>handleSIGHUP：是否响应 SIGHUP 信号，即挂起信号，例如终端退出操作，默认是 True</li><li>dumpio：是否将 Pyppeteer 的输出内容传给 process.stdout 对象和 process.stderr 对象，默认 False</li><li>userDatadir：用户数据文件夹，可保留一些个性化配置和操作记录</li><li>env：环境变量，可以传入字典形式的数据</li><li>devtools：是否自动为每一个页面开启调试工具，默认 False</li><li>logLevel(int|str)：日志级别，默认和 root logger 对象的级别相同</li><li>autoclose：当一些命令执行完后，是否自动关闭浏览器，默认 True</li><li>loop(asynciio.AbstractEventLoop)：时间循环对象</li></ul><p>Page 对象详解</p><ul><li><code>J</code> 方法对应 <code>querySelector()</code>，<code>JJ</code> 方法对应 <code>querySelectorAll()</code>；</li><li><code>bringToFront()</code>可以切换选项卡；</li><li><code>click()</code>模拟点击操作，第一个参数为选择器，第二个 <code>options=&#123;button，clickCount，delay&#125;</code>，button 表示鼠标按钮，有 left，middle，right，clickCount 表示点击次数，delay 表示延迟；</li><li><code>cookies()</code> 获取 Cookies</li><li><code>evaluate()</code> 执行 JavaScript 语句，<code>page.evaluate(&#39;&#39;&#39;() =&gt; &#123; return &#39;test&#39; &#125;&#39;&#39;&#39;)</code></li></ul><p>延迟等待方法，除了示例代码的 <code>waitForSelector</code>，还有 <code>waitForFunction, waitForNavigation, waitForRequest, waitForResponse, waitFor, waitForXPath</code></p><p>实战爬取 Selenium 那节的示例网站，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"><span class="keyword">from</span> pyppeteer.errors <span class="keyword">import</span> TimeoutError</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> makedirs</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(levelname)s: %(message)s&#x27;</span>)</span><br><span class="line">INDEX_URL = <span class="string">&#x27;https://spa2.scrape.center/page/&#123;page&#125;&#x27;</span></span><br><span class="line">TIMEOUT = <span class="number">10</span></span><br><span class="line">TOTAL_PAGE = <span class="number">1</span></span><br><span class="line">WINDOW_WIDTH, WINDOW_HEIGHT = <span class="number">1366</span>, <span class="number">768</span></span><br><span class="line">HEADLESS = <span class="literal">False</span></span><br><span class="line">RESULTS_DIR = <span class="string">&#x27;results&#x27;</span></span><br><span class="line"></span><br><span class="line">exists(RESULTS_DIR) <span class="keyword">or</span> makedirs(RESULTS_DIR)</span><br><span class="line">browser, tab = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">init</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    初始化浏览器，新建选项卡</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">global</span> browser, tab</span><br><span class="line">    browser = <span class="keyword">await</span> launch(headless=HEADLESS, args=[<span class="string">&#x27;--disable-infobars&#x27;</span>,  <span class="comment"># 隐藏提示条，设置浏览器宽高</span></span><br><span class="line">                                                    <span class="string">f&#x27;--window-size=<span class="subst">&#123;WINDOW_WIDTH&#125;</span>, <span class="subst">&#123;WINDOW_HEIGHT&#125;</span>&#x27;</span>])</span><br><span class="line">    tab = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> tab.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: WINDOW_WIDTH, <span class="string">&#x27;height&#x27;</span>: WINDOW_HEIGHT&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">scrape_page</span>(<span class="params">url, selector</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通用爬取方法</span></span><br><span class="line"><span class="string">    :param url:</span></span><br><span class="line"><span class="string">    :param selector:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;scraping %s&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">await</span> tab.goto(url)</span><br><span class="line">        <span class="keyword">await</span> tab.waitForSelector(selector, options=&#123;</span><br><span class="line">            <span class="string">&#x27;timeout&#x27;</span>: TIMEOUT * <span class="number">1000</span></span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="keyword">except</span> TimeoutError:</span><br><span class="line">        logging.error(<span class="string">&#x27;error occurred while scraping %s&#x27;</span>, url, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">scrape_index</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    列表页爬取</span></span><br><span class="line"><span class="string">    :param page: 页码</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    url = INDEX_URL.<span class="built_in">format</span>(page=page)</span><br><span class="line">    <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">parse_index</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    详情页 URL 解析</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 选择节点并执行对应 JavaScript 代码</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.item .name&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.href)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">scrape_detail</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    详情页爬取</span></span><br><span class="line"><span class="string">    :param url:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">await</span> scrape_page(url, <span class="string">&#x27;h2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    详情页解析</span></span><br><span class="line"><span class="string">    :return: dict</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    url = tab.url</span><br><span class="line">    name = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;h2&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">    categories = <span class="keyword">await</span> tab.querySelectorAllEval(<span class="string">&#x27;.categories button span&#x27;</span>, <span class="string">&#x27;nodes =&gt; nodes.map(node =&gt; node.innerText)&#x27;</span>)</span><br><span class="line">    cover = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.cover&#x27;</span>, <span class="string">&#x27;node =&gt; node.src&#x27;</span>)</span><br><span class="line">    score = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.score&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">    drama = <span class="keyword">await</span> tab.querySelectorEval(<span class="string">&#x27;.drama p&#x27;</span>, <span class="string">&#x27;node =&gt; node.innerText&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">        <span class="string">&#x27;categories&#x27;</span>: categories,</span><br><span class="line">        <span class="string">&#x27;cover&#x27;</span>: cover,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: score,</span><br><span class="line">        <span class="string">&#x27;drama&#x27;</span>: drama</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    保存数据</span></span><br><span class="line"><span class="string">    :param data: dict</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    name = data.get(<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">    data_path = <span class="string">f&#x27;<span class="subst">&#123;RESULTS_DIR&#125;</span>/<span class="subst">&#123;name&#125;</span>.json&#x27;</span></span><br><span class="line">    json.dump(data, <span class="built_in">open</span>(data_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">await</span> init()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, TOTAL_PAGE + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">await</span> scrape_index(page)</span><br><span class="line">            detail_urls = <span class="keyword">await</span> parse_index()</span><br><span class="line">            <span class="comment"># logging.info(&#x27;detail_urls |%s&#x27;, list(detail_urls))</span></span><br><span class="line">            <span class="keyword">for</span> detail_url <span class="keyword">in</span> <span class="built_in">list</span>(detail_urls):</span><br><span class="line">                logging.info(<span class="string">&#x27;get detail url %s&#x27;</span>, detail_url)</span><br><span class="line">                <span class="keyword">await</span> scrape_detail(detail_url)</span><br><span class="line">                detail_data = <span class="keyword">await</span> parse_detail()</span><br><span class="line">                logging.info(<span class="string">&#x27;detail data %s&#x27;</span>, detail_data)</span><br><span class="line">                <span class="keyword">await</span> save_data(detail_data)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure><h3 id="Playwright-的使用"><a href="#Playwright-的使用" class="headerlink" title="Playwright 的使用"></a>Playwright 的使用</h3><p>Playwright 是微软在2020年初开源的新一代自动化测试工具，功能与 Selenium 和 Pyppeteer 类似，支持当前所有主流浏览器，支持<strong>移动端页面测试</strong>，使用设备模拟技术，可以让我们在移动 Web 浏览器中测试响应式的 Web 应用程序。</p><p>支持两种编写模式，一种是和 Pyppeteer 一样的异步模式，一种是和 Selenium 一样的同步模式，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同步模式</span></span><br><span class="line"><span class="keyword">from</span> playwright.sync_api <span class="keyword">import</span> sync_playwright</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> sync_playwright() <span class="keyword">as</span> p:</span><br><span class="line">    <span class="keyword">for</span> browser_type <span class="keyword">in</span> [p.chromium, p.firefox, p.webkit]:</span><br><span class="line">        browser = browser_type.launch(headless=<span class="literal">False</span>)</span><br><span class="line">        page = browser.new_page()</span><br><span class="line">        page.goto(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line">        page.screenshot(path=<span class="string">f&#x27;screenshot-<span class="subst">&#123;browser_type.name&#125;</span>.png&#x27;</span>)</span><br><span class="line">        print(page.title)</span><br><span class="line">        browser.close()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 异步模式</span></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> playwright.async_api <span class="keyword">import</span> async_playwright</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> async_playwright() <span class="keyword">as</span> p:</span><br><span class="line">        <span class="keyword">for</span> browser_type <span class="keyword">in</span> [p.chromium, p.firefox, p.webkit]:</span><br><span class="line">            browser = <span class="keyword">await</span> browser_type.launch()</span><br><span class="line">            page = <span class="keyword">await</span> browser.new_page()</span><br><span class="line">            page.goto(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line">            page.screenshot(path=<span class="string">f&#x27;screenshot-<span class="subst">&#123;browser_type.name&#125;</span>.png&#x27;</span>)</span><br><span class="line">            print(<span class="keyword">await</span> page.title())</span><br><span class="line">            <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure><p>Playwright 还有一个强大的功能，是可以<strong>录制我们在浏览器中的操作并自动生成代码</strong>，可以通过调用 codegen 实现，查看参数可使用<code>playwright codegen --help</code></p><p>更多详情参考<a target="_blank" rel="noopener external nofollow noreferrer" href="https://playwright.dev/">官网</a></p><h3 id="CSS-位置偏移反爬案例分析与爬取实战"><a href="#CSS-位置偏移反爬案例分析与爬取实战" class="headerlink" title="CSS 位置偏移反爬案例分析与爬取实战"></a>CSS 位置偏移反爬案例分析与爬取实战</h3><p>本节了解 CSS 反爬虫的一些解决方案</p><p><img data-src="https://s2.loli.net/2022/03/01/F6GtieuvQAd5YOJ.png"></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://antispider3.scrape.center/">案例网站</a>，先用 Selenium 尝试爬取源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider3.scrape.center/&#x27;</span>)</span><br><span class="line">WebDriverWait(browser, <span class="number">10</span>).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, <span class="string">&#x27;.item&#x27;</span>)))</span><br><span class="line">html = browser.page_source</span><br><span class="line">doc = pq(html)</span><br><span class="line">names = doc(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> names.items():</span><br><span class="line">    print(name.text())</span><br><span class="line">browser.close()</span><br><span class="line"></span><br><span class="line">------------- result -------------</span><br><span class="line">Wonder</span><br><span class="line">风 家 白 清</span><br><span class="line">法 老 的 宠 妃 终 结 篇 （ 上 下 册 ）</span><br><span class="line">士 为 知 己 （ 全 二 册 ）</span><br><span class="line">那 些 年 ， 我 们 一 起 追 的 女 孩</span><br><span class="line">三 非 册 我 倾 （ 城 全 ）</span><br><span class="line">儿 那 朝 明 事 些</span><br><span class="line">我 书 忘 笑 的 和 你</span><br><span class="line">波 集 卷 一 第 小 全 王</span><br><span class="line">心 动 然 怦</span><br><span class="line">龙枪编年史（全<span class="number">3</span>册）</span><br><span class="line">龙 枪 传 奇 （ 全 三 册 ）</span><br><span class="line">之 明 街 黎</span><br><span class="line">认 理 及 心 学 启 示 其 知</span><br><span class="line">银河帝国<span class="number">2</span>：基地与帝国</span><br><span class="line">银 河 帝 国 ： 基 地</span><br><span class="line">学 教 年 小 - 全 材 解 下 四 级 语 文</span><br><span class="line">越界言论（第<span class="number">3</span>卷）</span><br></pre></td></tr></table></figure><p>可以看到标题的文字顺序很多是乱的，检测网页源代码：</p><p><img data-src="https://s2.loli.net/2022/03/01/xeHsFJqp3Mblwor.png"></p><p>发现网页用 CSS 控制了文字的偏移位置，解决思路就是获取每个 <code>span</code> 节点的 <code>style</code>属性，提取偏移值，在排序即可得出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> groups <span class="keyword">as</span> groups</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_name</span>(<span class="params">name_html</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    解析标题</span></span><br><span class="line"><span class="string">    :param name_html: 标题节点源代码</span></span><br><span class="line"><span class="string">    :return: title(str)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 过滤正常的标题</span></span><br><span class="line">    has_whole = name_html(<span class="string">&#x27;.whole&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> has_whole:</span><br><span class="line">        <span class="keyword">return</span> name_html.text()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        chars = name_html(<span class="string">&#x27;.char&#x27;</span>)</span><br><span class="line">        items = []</span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> chars.items():</span><br><span class="line">            items.append(&#123;</span><br><span class="line">                <span class="string">&#x27;text&#x27;</span>: char.text().strip(),</span><br><span class="line">                <span class="string">&#x27;left&#x27;</span>: <span class="built_in">int</span>(re.search(<span class="string">&#x27;(\d+)px&#x27;</span>, char.attr(<span class="string">&#x27;style&#x27;</span>)).group(<span class="number">1</span>))</span><br><span class="line">            &#125;)</span><br><span class="line">        items = <span class="built_in">sorted</span>(items, key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;left&#x27;</span>], reverse=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([item[<span class="string">&#x27;text&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> items])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider3.scrape.center/&#x27;</span>)</span><br><span class="line">WebDriverWait(browser, <span class="number">10</span>).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, <span class="string">&#x27;.item&#x27;</span>)))</span><br><span class="line">html = browser.page_source</span><br><span class="line">doc = pq(html)</span><br><span class="line">names = doc(<span class="string">&#x27;.item .name&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> name_html <span class="keyword">in</span> names.items():</span><br><span class="line">    name = parse_name(name_html)</span><br><span class="line">    print(name)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure><h3 id="字体反爬案例分析与爬取实战"><a href="#字体反爬案例分析与爬取实战" class="headerlink" title="字体反爬案例分析与爬取实战"></a>字体反爬案例分析与爬取实战</h3><p>本节的反爬虫案例，将真实数据隐藏在字体文件中，所以即可得到了网页源码也无法获取想要的数据。</p><p><img data-src="https://s2.loli.net/2022/03/01/pAh9bFIc7sYV81B.png"></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://antispider4.scrape.center/">案例网站</a>，先用 Selenium 尝试爬取源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider4.scrape.center/&#x27;</span>)</span><br><span class="line">WebDriverWait(browser, <span class="number">10</span>).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, <span class="string">&#x27;.item&#x27;</span>)))</span><br><span class="line">html = browser.page_source</span><br><span class="line">doc = pq(html)</span><br><span class="line">items = doc(<span class="string">&#x27;.item&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> items.items():</span><br><span class="line">    name = item(<span class="string">&#x27;.name&#x27;</span>).text()</span><br><span class="line">    categories = [x.text() <span class="keyword">for</span> x <span class="keyword">in</span> item(<span class="string">&#x27;.categories button span&#x27;</span>).items()]</span><br><span class="line">    score = item(<span class="string">&#x27;.score&#x27;</span>).text()</span><br><span class="line">    print(<span class="string">f&#x27;name: <span class="subst">&#123;name&#125;</span> categories: <span class="subst">&#123;categories&#125;</span> score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line">browser.close()</span><br><span class="line"></span><br><span class="line">------------- result -------------</span><br><span class="line">name: 霸王别姬 - Farewell My Concubine categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: </span><br><span class="line">name: 这个杀手不太冷 - Léon categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;动作&#x27;</span>, <span class="string">&#x27;犯罪&#x27;</span>] score: </span><br><span class="line">name: 肖申克的救赎 - The Shawshank Redemption categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;犯罪&#x27;</span>] score: </span><br><span class="line">name: 泰坦尼克号 - Titanic categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;灾难&#x27;</span>] score: </span><br><span class="line">name: 罗马假日 - Roman Holiday categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: </span><br><span class="line">name: 唐伯虎点秋香 - Flirting Scholar categories: [<span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;古装&#x27;</span>] score: </span><br><span class="line">name: 乱世佳人 - Gone <span class="keyword">with</span> the Wind categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;历史&#x27;</span>, <span class="string">&#x27;战争&#x27;</span>] score: </span><br><span class="line">name: 喜剧之王 - The King of Comedy categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: </span><br><span class="line">name: 楚门的世界 - The Truman Show categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;科幻&#x27;</span>] score: </span><br><span class="line">name: 狮子王 - The Lion King categories: [<span class="string">&#x27;动画&#x27;</span>, <span class="string">&#x27;歌舞&#x27;</span>, <span class="string">&#x27;冒险&#x27;</span>] score: </span><br></pre></td></tr></table></figure><p>发现没有 score，检测网页源码，score 值并不在页面源码中，而是使用 ::before 字段插入伪节点的方法来显示内容的。</p><p><img data-src="https://s2.loli.net/2022/03/01/JyuxIQwUtGKdMel.png"></p><p>通过追踪 CSS 源代码，可以找到 class 取值和 content 字段值的映射，而这个 CSS 文件的位置是 <code>https://antispider4.scrape.center/css/app.654ba59e.css</code>。</p><p><img data-src="https://s2.loli.net/2022/03/01/6YPXBhzTH71Fpwo.png"></p><p>我们可以尝试用 requests 库读取，并通过正则表达式提取映射关系，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://antispider4.scrape.center/css/app.654ba59e.css&#x27;</span></span><br><span class="line"></span><br><span class="line">response = requests.get(url)</span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;\.icon-(.*?):before\&#123;content:&quot;(.*?)&quot;\&#125;&#x27;</span>)</span><br><span class="line">results = re.findall(pattern, response.text)</span><br><span class="line">icon_map = &#123;item[<span class="number">0</span>]: item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> results&#125;</span><br><span class="line">print(icon_map)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2022/03/01/x1Ty6G8ZisWg245.png"></p><p>通过代码得到一个映射表，通过网页源码中的索引即可得到对应数值，如 “789”，对应 “9”，下面展示修改后代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://antispider4.scrape.center/css/app.654ba59e.css&#x27;</span></span><br><span class="line"></span><br><span class="line">response = requests.get(url)</span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;\.icon-(.*?):before\&#123;content:&quot;(.*?)&quot;\&#125;&#x27;</span>)</span><br><span class="line">results = re.findall(pattern, response.text)</span><br><span class="line">icon_map = &#123;item[<span class="number">0</span>]: item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> results&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_score</span>(<span class="params">item</span>):</span></span><br><span class="line">    elements = item(<span class="string">&#x27;.icon&#x27;</span>)</span><br><span class="line">    icon_values = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> elements.items():</span><br><span class="line">        class_name = (element.attr(<span class="string">&#x27;class&#x27;</span>))</span><br><span class="line">        icon_key = re.search(<span class="string">&#x27;icon-(\d+)&#x27;</span>, class_name).group(<span class="number">1</span>)</span><br><span class="line">        icon_value = icon_map[icon_key]</span><br><span class="line">        icon_values.append(icon_value)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(icon_values)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;useAutomationExtension&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">browser = webdriver.Chrome(options=options)</span><br><span class="line">browser.get(<span class="string">&#x27;https://antispider4.scrape.center/&#x27;</span>)</span><br><span class="line">WebDriverWait(browser, <span class="number">10</span>).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, <span class="string">&#x27;.item&#x27;</span>)))</span><br><span class="line">html = browser.page_source</span><br><span class="line">doc = pq(html)</span><br><span class="line">items = doc(<span class="string">&#x27;.item&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> items.items():</span><br><span class="line">    name = item(<span class="string">&#x27;.name&#x27;</span>).text()</span><br><span class="line">    categories = [x.text() <span class="keyword">for</span> x <span class="keyword">in</span> item(<span class="string">&#x27;.categories button span&#x27;</span>).items()]</span><br><span class="line">    score = parse_score(item)</span><br><span class="line">    print(<span class="string">f&#x27;name: <span class="subst">&#123;name&#125;</span> categories: <span class="subst">&#123;categories&#125;</span> score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line">browser.close()</span><br><span class="line"></span><br><span class="line">------------- result -------------</span><br><span class="line">name: 霸王别姬 - Farewell My Concubine categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 这个杀手不太冷 - Léon categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;动作&#x27;</span>, <span class="string">&#x27;犯罪&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 肖申克的救赎 - The Shawshank Redemption categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;犯罪&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 泰坦尼克号 - Titanic categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;灾难&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 罗马假日 - Roman Holiday categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 唐伯虎点秋香 - Flirting Scholar categories: [<span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;古装&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 乱世佳人 - Gone <span class="keyword">with</span> the Wind categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>, <span class="string">&#x27;历史&#x27;</span>, <span class="string">&#x27;战争&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 喜剧之王 - The King of Comedy categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;喜剧&#x27;</span>, <span class="string">&#x27;爱情&#x27;</span>] score: <span class="number">9.5</span></span><br><span class="line">name: 楚门的世界 - The Truman Show categories: [<span class="string">&#x27;剧情&#x27;</span>, <span class="string">&#x27;科幻&#x27;</span>] score: <span class="number">9.0</span></span><br><span class="line">name: 狮子王 - The Lion King categories: [<span class="string">&#x27;动画&#x27;</span>, <span class="string">&#x27;歌舞&#x27;</span>, <span class="string">&#x27;冒险&#x27;</span>] score: <span class="number">9.0</span></span><br></pre></td></tr></table></figure><p>本案例较为特殊，据此也明白了即使获取了源代码也不一定能得到关键信息，需要仔细观察一些规律才可以。</p></div><div class="popular-posts-header">推荐阅读</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\57744bfb.html" rel="bookmark">爬虫笔记六 -- 异步爬虫</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\4ca1a587.html" rel="bookmark">爬虫笔记五 -- Ajax 数据爬取</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\39ed07bf.html" rel="bookmark">爬虫笔记四 -- 数据的存储</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\79659fc4.html" rel="bookmark">爬虫笔记三 -- 解析库的使用</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\archives\50c99347.html" rel="bookmark">爬虫笔记二 -- 基本库的使用</a></div></li></ul><footer class="post-footer"><div class="reward-container"><div>Buy me a coffee</div><button onclick='document.querySelector(".post-reward").classList.toggle("active")'>赞赏</button><div class="post-reward"><div><img src="/images/wechat-pay.png" alt="Hyacinth 微信"> <span>微信</span></div><div><img src="/images/alipay-pay.png" alt="Hyacinth 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Hyacinth</li><li><strong>修改时间：</strong> <time title="修改时间：2022-03-01 15:56:25" itemprop="dateModified" datetime="2022-03-01T15:56:25+08:00">今天15:56</time></li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://hyacinth.fit/archives/d1c41f0f.html" title="爬虫笔记七 -- JavaScript 动态渲染页面爬取">https://hyacinth.fit/archives/d1c41f0f.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/images/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i> </span><span class="label">WeChat</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-tags"><a href="/tags/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/" rel="tag"><i class="fa fa-tag"></i> 爬虫笔记</a></div><div class="post-nav"><div class="post-nav-item"><a href="/archives/57744bfb.html" rel="prev" title="爬虫笔记六 -- 异步爬虫"><i class="fa fa-chevron-left"></i> 爬虫笔记六 -- 异步爬虫</a></div><div class="post-nav-item"></div></div></footer></article></div><div class="comments gitalk-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Hyacinth</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">243k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">3:41</span></span></div></div></footer><script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>// 代码折叠<script src="/js/code-unfold.js"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="leancloud_visitors" type="application/json">{&quot;enable&quot;:true,&quot;app_id&quot;:&quot;mXCXRvyDJTe1MizGNz8MBQCC-MdYXbMMI&quot;,&quot;app_key&quot;:&quot;NKjSKtz16WlOVxKDRa1tJNgl&quot;,&quot;server_url&quot;:null,&quot;security&quot;:false}</script><script src="/js/third-party/statistics/lean-analytics.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;,&quot;integrity&quot;:&quot;sha256-ncNI9OXOS5Ek4tzVYiOMmN&#x2F;KKCPZ6V0Cpv2P&#x2F;zHntiA&#x3D;&quot;}}</script><script src="/js/third-party/math/mathjax.js"></script><script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script><script>var options={bottom:"64px",right:"unset",left:"32px",time:"0.5s",mixColor:"transparent",backgroundColor:"transparent",buttonColorDark:"#100f2c",buttonColorLight:"#fff",saveInCookies:!0,label:"🌓",autoMatchOsTheme:!0};const darkmode=new Darkmode(options);window.darkmode=darkmode,darkmode.showWidget()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous"><script class="next-config" data-name="gitalk" type="application/json">{&quot;enable&quot;:true,&quot;github_id&quot;:&quot;SpeedPromise&quot;,&quot;repo&quot;:&quot;blog-comments&quot;,&quot;client_id&quot;:&quot;c87c14d15109ca258c8c&quot;,&quot;client_secret&quot;:&quot;fcb23a076c153b6a22f7dc957f54510992dc0342&quot;,&quot;admin_user&quot;:&quot;SpeedPromise&quot;,&quot;distraction_free_mode&quot;:true,&quot;proxy&quot;:&quot;https:&#x2F;&#x2F;cors-anywhere.azm.workers.dev&#x2F;https:&#x2F;&#x2F;github.com&#x2F;login&#x2F;oauth&#x2F;access_token&quot;,&quot;language&quot;:null,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;gitalk@1.7.2&#x2F;dist&#x2F;gitalk.min.js&quot;,&quot;integrity&quot;:&quot;sha256-Pmj85ojLaPOWwRtlMJwmezB&#x2F;Qg8BzvJp5eTzvXaYAfA&#x3D;&quot;},&quot;path_md5&quot;:&quot;27fc42b30cb782a169e6cac80a2bb4d7&quot;}</script><script src="/js/third-party/comments/gitalk.js"></script><script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script async src="/js/cursor/fireworks.js"></script></body></html>